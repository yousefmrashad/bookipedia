# Utils
import json
import logging
import os
from typing import Annotated

import requests
import uvicorn

# API
from fastapi import BackgroundTasks, FastAPI, Query
from fastapi.concurrency import run_in_threadpool
from fastapi.responses import StreamingResponse

# TTS
from piper import PiperVoice
from pydantic import BaseModel

from .preprocessing.document import Document
from .preprocessing.embedding import HFEmbedding
from .rag.rag_pipeline import RAGPipeline
from .utils.config import (
    ACKNOWLEDGE_URL,
    API_HOST,
    API_PORT,
    CHAT_SUMMARY_URL,
    PIPER_CONFIG_PATH,
    PIPER_MODEL_PATH,
    POST_HOCR_URL,
)
from .utils.db_config import DB

# ===================================================================== #


# Schemas
class ChatParams(BaseModel):
    user_prompt: str
    chat_summary: str
    chat: str
    doc_ids: list[str] = None


class TTSText(BaseModel):
    text: str


# --------------------------------------------------------------------- #

# Initializations
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s", force=True
)
logger = logging.getLogger(__name__)

voice = PiperVoice.load(PIPER_MODEL_PATH, PIPER_CONFIG_PATH, use_cuda=False)


app = FastAPI(
    title="Bookipedia AI Server",
    description="Bookipedia AI Server is an AI inference server for the Bookipedia application, which serves as an online library with an AI-powered reading assistant. The server utilizes state-of-the-art language models (LLMs), optical character recognition (OCR), and text-to-speech (TTS) features.",
    version="1.0.0",
)
embedding_model = HFEmbedding()
client = DB().connect()
rag_pipeline = RAGPipeline(embedding_model, client)
# --------------------------------------------------------------------- #


# Background Tasks
def process_document(doc: Document, doc_id: str):
    """
    Processes a document by either pre-processing it if it's text-based or applying OCR and then pre-processing it.
    It sends a patch request to the server to acknowledge the completion of the processing.
    If the document is not text-based, it sends a POST request to the OCR server to get the HOCR file.
    After processing, it removes the original document file.

    Parameters:
    doc (Document): The document object to be processed.
    doc_id (str): The unique identifier of the document.

    Returns:
    None
    """
    logger.info(f"Processing document {doc_id}")
    try:
        if doc.text_based:
            doc.process_document(embedding_model, client)
            requests.patch(
                ACKNOWLEDGE_URL + doc.doc_id,
                json={"message": "Document preprocessing completed."},
            )
            logger.info(f"Document {doc_id} preprocessed successfully.")
        else:
            doc.get_text_based_document()
            with open(doc.doc_path, "rb") as file:
                response = requests.post(
                    POST_HOCR_URL + doc_id,
                    files={"file": (file.name, file, "application/pdf")},
                )
            if response.status_code == 202:
                doc.doc_id = response.json()["file_id"]
                doc.process_document(embedding_model, client)
                requests.patch(
                    ACKNOWLEDGE_URL + doc.doc_id,
                    json={"message": "Document OCR and preprocessing completed."},
                )
                logger.info(
                    f"HOCR file for document {doc_id} posted and processed successfully."
                )
            else:
                logger.error(
                    f"Failed to post HOCR file for document {doc_id}. Status code: {response.status_code}, Text: {response.text}"
                )
        os.remove(doc.doc_path)
    except Exception as e:
        logger.exception(
            f"Exception occurred while processing document {doc_id}: {str(e)}"
        )


# ---------------------------------------------- #


def summarize_chat(chat_id: str, user_prompt: str, response: str, prev_summary: str):
    """
    Summarizes a chat conversation based on the provided response, user prompt, and previous summary.

    Parameters:
    chat_id (str): The unique identifier of the chat conversation.
    response (str): The response generated by the chatbot for the given user prompt.
    user_prompt (str): The user's input prompt that triggered the chatbot's response.
    prev_summary (str): The previous summary of the chat conversation.

    Returns:
    None: This function does not return any value. It updates the chat summary in the database.
    """
    logger.info(f"Summarizing chat {chat_id}")
    try:
        chat_summary = rag_pipeline.generate_chat_summary(
            user_prompt, response, prev_summary
        )
        response = requests.patch(
            CHAT_SUMMARY_URL + chat_id, json={"chat_summary": chat_summary}
        )
        if response.status_code == 202:
            logger.info(f"Chat summary for chat {chat_id} updated successfully.")
        else:
            logger.error(
                f"Failed to update chat summary for chat {chat_id}. Status code: {response.status_code}"
            )
    except Exception as e:
        logger.exception(
            f"Exception occurred while summarizing chat {chat_id}: {str(e)}"
        )


# -------------------------------------------------- #


# Endpoints
@app.get("/")
def root():
    """
    Root endpoint called when the server is accessed at the root URL.

    Returns:
    A JSON response with the message "bookipedia".
    """
    logger.info("Root endpoint called")
    return {"message": "bookipedia"}


# -------------------------------------------------- #


@app.post("/add_document/{doc_id}")
def add_document(
    background_tasks: BackgroundTasks, doc_id: str, url: str, lib_doc: bool = False
):
    """
    Adds a document to the server.

    Parameters:
    background_tasks (BackgroundTasks): An object used to schedule background tasks.
    doc_id (str): The unique identifier of the document.
    url (str): The URL of the document to be added.
    lib_doc (bool, optional): A flag indicating whether the document is a library document. Defaults to False.

    Returns:
    A JSON response with the message "Document added successfully" if the document was successfully added.
    Otherwise, it returns a JSON response with the message "Failed to add document" and the status code of the response.
    """
    logger.info(
        f"Add document endpoint called with doc_id: {doc_id}, url: {url}, lib_doc: {lib_doc}"
    )
    try:
        response = requests.get(url, stream=True)
        if response.status_code == 200:
            doc_path = doc_id + ".pdf"
            with open(doc_path, "wb") as file:
                file.write(response.content)
            logger.info(f"File {doc_path} downloaded successfully.")
        else:
            logger.error(
                f"Failed to download file from {url}. Status code: {response.status_code}"
            )
            return {
                "message": "Failed to download file.",
                "status code": response.status_code,
            }

        doc = Document(doc_path, doc_id, lib_doc)
        background_tasks.add_task(process_document, doc, doc_id)
        if doc.text_based:
            logger.info(f"Document {doc_id} is text-based. Preprocessing started.")
            return {
                "message": "Document is text-based. Preprocessing started.",
                "OCR": False,
            }
        else:
            logger.info(f"Document {doc_id} is not text-based. Applying OCR.")
            return {"message": "Document is not text-based. Applying OCR.", "OCR": True}
    except Exception as e:
        logger.exception(f"Exception occurred while adding document {doc_id}: {str(e)}")
        return {"message": "An error occurred while adding the document."}


# -------------------------------------------------- #


@app.delete("/delete_document/{doc_id}")
def delete_document(doc_id: str):
    """
    Deletes a document from the database.

    Parameters:
    doc_id (str): The unique identifier of the document to be deleted.

    Returns:
    A JSON response with a message indicating the success or failure of the deletion operation.
    """
    logger.info(f"Delete document endpoint called with doc_id: {doc_id}")
    try:
        rag_pipeline.db.delete(doc_id)
        logger.info(f"Document {doc_id} deleted successfully.")
        return {"message": "Document deleted successfully."}
    except Exception as e:
        logger.exception(
            f"Exception occurred while deleting document {doc_id}: {str(e)}"
        )
        return {"message": "An error occurred while deleting the document."}


# -------------------------------------------------- #


@app.get("/chat_response/{chat_id}")
async def chat_response(
    background_tasks: BackgroundTasks,
    chat_id: str,
    chat_params: ChatParams,
    enable_web_retrieval: bool = False,
):
    """
    Generates a response to a chat conversation.

    Parameters:
    background_tasks (BackgroundTasks): An object used to schedule background tasks.
    chat_id (str): The unique identifier of the chat conversation.
    chat_params (ChatParams): A ChatParams object containing the chat conversation parameters.
    enable_web_retrieval (bool, optional): A flag indicating whether to enable web retrieval. Defaults to False.

    Returns:
    A StreamingResponse object containing the generated response to the chat conversation.
    """
    logger.info(
        f"Chat response endpoint called with chat_id: {chat_id}, enable_web_retrieval: {enable_web_retrieval}"
    )
    try:
        # Extract parameters
        user_prompt = chat_params.user_prompt
        chat_summary = chat_params.chat_summary
        chat = chat_params.chat
        doc_ids = chat_params.doc_ids

        # Generate retrieval method & retrieval query
        retrieval_method, retrieval_query = await rag_pipeline.generate_retrieval_query(
            user_prompt, chat_summary
        )

        # Generate context
        context, metadata = await run_in_threadpool(
            rag_pipeline.generate_context,
            retrieval_method,
            retrieval_query,
            doc_ids,
            enable_web_retrieval,
        )

        # Response generator
        async def stream_generator():
            answer = rag_pipeline.generate_answer(user_prompt, chat, context)

            # Yield data stream
            response = ""
            async for chunk in answer:
                response += chunk
                yield chunk.encode("utf-8")

            yield b'\n\n[sources]\n\n{"sources": '
            yield json.dumps(metadata).encode("utf-8") + b"}"

            # Add chat summary to background tasks
            background_tasks.add_task(
                summarize_chat, chat_id, user_prompt, response, chat_summary
            )

        logger.info(f"Generated context and response for chat_id: {chat_id}")
        return StreamingResponse(stream_generator(), media_type="text/plain")

    except Exception as e:
        logger.exception(
            f"Exception occurred while generating chat response for chat_id {chat_id}: {str(e)}"
        )
        return {"message": "An error occurred while generating the chat response."}


# -------------------------------------------------- #


@app.get("/summarize_pages/{doc_id}")
async def summarize_pages(doc_id: str, start_page: int, end_page: int):
    """
    Summarizes the specified pages of a document.

    Parameters:
    doc_id (str): The unique identifier of the document to be summarized.
    pages (list[int]): The list of page numbers to be summarized.

    Returns:
    A JSON response with a message indicating the success or failure of the summarization operation.
    """
    logger.info(
        f"Summarize pages endpoint called with doc_id: {doc_id}, pages: {start_page} to {end_page}"
    )
    pages = list(range(start_page, end_page + 1))
    try:

        async def stream_generator():
            summary = await rag_pipeline.summarize_pages(doc_id, pages)
            async for chunk in summary:
                yield chunk.encode("utf-8")

        logger.info(f"Summarization for document {doc_id} pages {pages} started")
        return StreamingResponse(stream_generator(), media_type="text/plain")

    except Exception as e:
        logger.exception(
            f"Exception occurred in summarizing pages for doc_id {doc_id}: {str(e)}"
        )
        return {
            "message": "An error occurred during the summarization of the specified pages."
        }


# -------------------------------------------------- #


@app.get("/tts/")
def text_to_speech(tts_text: TTSText, speed: float = 1):
    """
    Generates an audio stream from the given text.

    Parameters:
    tts_text (TTSText): A TTSText object containing the text to be synthesized.
    speed (float, optional): The speed at which the text should be synthesized. Defaults to 1.

    Returns:
    A StreamingResponse object containing the synthesized audio stream.
    """
    logger.info(f"TTS endpoint called with text: {tts_text.text}, speed: {speed}")
    try:
        text = tts_text.text

        def synthesize_audio():
            lines = text.split("\n")
            for line in lines:
                audio_stream = voice.synthesize_stream_raw(line, length_scale=1 / speed)
                for audio_bytes in audio_stream:
                    yield audio_bytes

        logger.info("TTS synthesis started")
        return StreamingResponse(synthesize_audio(), media_type="audio/raw")
    except Exception as e:
        logger.exception(f"Exception occurred in TTS synthesis: {str(e)}")
        return {"message": "An error occurred during TTS synthesis."}


# -------------------------------------------------- #


@app.get("/tts_pages/{doc_id}")
def pages_to_speech(
    doc_id: str, pages: Annotated[list[int], Query()], speed: float = 1
):
    """
    Generates an audio stream from the specified pages of a document.

    Parameters:
    doc_id (str): The unique identifier of the document.
    pages (list[int]): The list of page numbers to be synthesized.
    speed (float, optional): The speed at which the text should be synthesized. Defaults to 1.

    Returns:
    A StreamingResponse object containing the synthesized audio stream.
    """
    logger.info(
        f"TTS pages endpoint called with doc_id: {doc_id}, pages: {pages}, speed: {speed}"
    )
    try:

        def synthesize_audio():
            for page in pages:
                text = rag_pipeline.get_page_text(doc_id, page)
                lines = text.split("\n")
                for line in lines:
                    audio_stream = voice.synthesize_stream_raw(
                        line, length_scale=1 / speed
                    )
                    for audio_bytes in audio_stream:
                        yield audio_bytes

        logger.info(f"TTS synthesis for document {doc_id} pages {pages} started")
        return StreamingResponse(synthesize_audio(), media_type="audio/raw")
    except Exception as e:
        logger.exception(
            f"Exception occurred in TTS pages synthesis for doc_id {doc_id}: {str(e)}"
        )
        return {
            "message": "An error occurred during TTS synthesis for the specified pages."
        }


# -------------------------------------------------- #


def main():
    logger.info("Starting Bookipedia AI Server")
    uvicorn.run(app, host=API_HOST, port=API_PORT)


if __name__ == "__main__":
    main()


# --------------------------------------------------------------------- #
